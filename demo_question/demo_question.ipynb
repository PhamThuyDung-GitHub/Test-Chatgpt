{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import chromadb\n",
    "from chromadb.config import Settings\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import numpy as np\n",
    "nltk.download(\"punkt\", quiet=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Câu hỏi</th>\n",
       "      <th>Câu trả lời</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Các quả có mùi vị như thế nào?</td>\n",
       "      <td>Quả cam ngon. Quả táo dở. Quả chanh chua. Quả ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Các quả có hình dáng như thế nào?</td>\n",
       "      <td>Quả cam có hình tròn. Quả táo có hình tròn, hơ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Câu hỏi  \\\n",
       "0     Các quả có mùi vị như thế nào?   \n",
       "1  Các quả có hình dáng như thế nào?   \n",
       "\n",
       "                                         Câu trả lời  \n",
       "0  Quả cam ngon. Quả táo dở. Quả chanh chua. Quả ...  \n",
       "1  Quả cam có hình tròn. Quả táo có hình tròn, hơ...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path = r'C:\\Users\\ungdu\\Downloads\\Test_Chatgpt\\test_data.csv' #import data\n",
    "data = pd.read_csv(file_path)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\ungdu\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Các quả có mùi vị như thế nào?']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "['Các quả có hình dáng như thế nào?']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from IPython.display import display\n",
    "\n",
    "# Tải bộ dữ liệu phân tách câu của NLTK nếu chưa có\n",
    "nltk.download('punkt')\n",
    "\n",
    "\n",
    "# Danh sách chứa tất cả các câu đã phân tách\n",
    "all_sentences = []\n",
    "\n",
    "# Lặp qua từng dòng của DataFrame\n",
    "for _, row in data.iterrows():\n",
    "    # Lấy nội dung cột \"Câu trả lời\"\n",
    "    text = row.get(\"Câu hỏi\", \"\")\n",
    "    \n",
    "    # Kiểm tra nếu text không rỗng và là chuỗi\n",
    "    if text and isinstance(text, str):\n",
    "        # Chia văn bản thành các câu\n",
    "        sentences = nltk.sent_tokenize(text)\n",
    "        \n",
    "        # Hiển thị từng câu đã tách (chỉ để kiểm tra)\n",
    "        display(sentences)\n",
    "        \n",
    "        # Thêm các câu này vào danh sách tổng hợp\n",
    "        all_sentences.extend(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Đã lưu 2 câu vào file 'extracted_sentences.csv'.\n"
     ]
    }
   ],
   "source": [
    "# Tạo DataFrame từ danh sách các câu\n",
    "sentences_df = pd.DataFrame({'Câu hỏi': all_sentences})\n",
    "\n",
    "# Lưu DataFrame vào file CSV\n",
    "output_filename = 'extracted_sentences.csv'\n",
    "sentences_df.to_csv(output_filename, index=False, encoding='utf-8-sig')\n",
    "\n",
    "print(f\"Đã lưu {len(all_sentences)} câu vào file '{output_filename}'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                             Câu hỏi\n",
      "0     Các quả có mùi vị như thế nào?\n",
      "1  Các quả có hình dáng như thế nào?\n",
      "Đã tải 2 câu từ 'extracted_sentences.csv'.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Đọc file CSV chứa các câu đã được tách\n",
    "sentences_df = pd.read_csv('extracted_sentences.csv', encoding='utf-8-sig')\n",
    "print(sentences_df)\n",
    "# Hiển thị số lượng câu đã được tải\n",
    "print(f\"Đã tải {len(sentences_df)} câu từ 'extracted_sentences.csv'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ma trận TF-IDF có kích thước: (2, 10)\n",
      "Mẫu độ tương đồng giữa các câu:\n",
      "[[1.         0.60297482]\n",
      " [0.60297482 1.        ]]\n"
     ]
    }
   ],
   "source": [
    "# Bước 3: Vector hóa các câu sử dụng TF-IDF\n",
    "vectorizer = TfidfVectorizer()\n",
    "tfidf_matrix = vectorizer.fit_transform(sentences_df['Câu hỏi'])\n",
    "\n",
    "# Hiển thị kích thước ma trận TF-IDF\n",
    "print(f\"Ma trận TF-IDF có kích thước: {tfidf_matrix.shape}\")\n",
    "\n",
    "# Bước 2: Tính độ tương đồng giữa các câu bằng cosine similarity\n",
    "# Tính ma trận độ tương đồng giữa các câu\n",
    "cosine_sim = cosine_similarity(tfidf_matrix, tfidf_matrix)\n",
    "\n",
    "# Hiển thị một phần ma trận độ tương đồng\n",
    "print(\"Mẫu độ tương đồng giữa các câu:\")\n",
    "print(cosine_sim[:5, :5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Đã lưu ma trận TF-IDF vào file 'tfidf_matrix.csv'.\n"
     ]
    }
   ],
   "source": [
    "# 1. Lưu Ma Trận TF-IDF\n",
    "# Chuyển đổi ma trận TF-IDF thành DataFrame\n",
    "# Lưu ý: Nếu số lượng từ vựng (features) lớn, việc lưu trữ có thể tiêu tốn nhiều dung lượng\n",
    "tfidf_df = pd.DataFrame(tfidf_matrix.toarray(), columns=vectorizer.get_feature_names_out())\n",
    "\n",
    "# Lưu DataFrame TF-IDF vào CSV\n",
    "tfidf_output_filename = 'tfidf_matrix.csv'\n",
    "tfidf_df.to_csv(tfidf_output_filename, index=False, encoding='utf-8-sig')\n",
    "\n",
    "print(f\"Đã lưu ma trận TF-IDF vào file '{tfidf_output_filename}'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Đã lưu ma trận cosine similarity vào file 'cosine_similarity_matrix.csv'.\n"
     ]
    }
   ],
   "source": [
    "# 2. Lưu Ma Trận Cosine Similarity\n",
    "# Chuyển đổi ma trận cosine similarity thành DataFrame\n",
    "cosine_sim_df = pd.DataFrame(cosine_sim, index=sentences_df.index, columns=sentences_df.index)\n",
    "\n",
    "# Lưu DataFrame cosine similarity vào CSV\n",
    "cosine_sim_output_filename = 'cosine_similarity_matrix.csv'\n",
    "cosine_sim_df.to_csv(cosine_sim_output_filename, index=True, encoding='utf-8-sig')\n",
    "\n",
    "print(f\"Đã lưu ma trận cosine similarity vào file '{cosine_sim_output_filename}'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Độ tương đồng giữa câu 1 và câu 2: 0.60\n",
      "Đã lưu 1 chunks vào file 'chunked_sentences.csv'.\n"
     ]
    }
   ],
   "source": [
    "# Bước 4: Gép các câu lại với nhau dựa trên độ tương đồng\n",
    "\n",
    "# Thiết lập ngưỡng độ tương đồng\n",
    "SIMILARITY_THRESHOLD = 0.3 # Bạn có thể điều chỉnh ngưỡng này\n",
    "\n",
    "# Danh sách để lưu các chunk\n",
    "chunks = []\n",
    "current_chunk = sentences_df.iloc[0]['Câu hỏi']  # Bắt đầu với câu đầu tiên trong cột \"Câu hỏi\"\n",
    "\n",
    "for i in range(1, len(sentences_df)):\n",
    "    prev_sentence = sentences_df.iloc[i - 1]['Câu hỏi']\n",
    "    current_sentence = sentences_df.iloc[i]['Câu hỏi']\n",
    "    \n",
    "    # Vector hóa câu hiện tại và câu trước đó\n",
    "    prev_vector = vectorizer.transform([prev_sentence])\n",
    "    current_vector = vectorizer.transform([current_sentence])\n",
    "    \n",
    "    # Tính độ tương đồng giữa câu trước và câu hiện tại\n",
    "    similarity = cosine_similarity(prev_vector, current_vector)[0][0]\n",
    "    \n",
    "    print(f\"Độ tương đồng giữa câu {i} và câu {i+1}: {similarity:.2f}\")\n",
    "    \n",
    "    if similarity >= SIMILARITY_THRESHOLD:\n",
    "        # Gép câu hiện tại vào chunk hiện tại\n",
    "        current_chunk += ' ' + current_sentence\n",
    "    else:\n",
    "        # Thêm chunk hiện tại vào danh sách và bắt đầu chunk mới\n",
    "        chunks.append(current_chunk)\n",
    "        current_chunk = current_sentence\n",
    "\n",
    "# Thêm chunk cuối cùng vào danh sách\n",
    "chunks.append(current_chunk)\n",
    "\n",
    "# Tạo DataFrame từ các chunk\n",
    "chunks_df = pd.DataFrame({'Chunk': chunks})\n",
    "\n",
    "# Lưu các chunk vào file CSV mới\n",
    "output_chunk_filename = 'chunked_sentences.csv'\n",
    "chunks_df.to_csv(output_chunk_filename, index=False, encoding='utf-8-sig')\n",
    "\n",
    "print(f\"Đã lưu {len(chunks)} chunks vào file '{output_chunk_filename}'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dữ liệu với cột 'Chunk':\n",
      "                             Câu hỏi  \\\n",
      "0     Các quả có mùi vị như thế nào?   \n",
      "1  Các quả có hình dáng như thế nào?   \n",
      "\n",
      "                                               Chunk  \n",
      "0  Các quả có mùi vị như thế nào? Các quả có hình...  \n",
      "1  Các quả có mùi vị như thế nào? Các quả có hình...  \n",
      "\n",
      "Dữ liệu đã được lưu vào file 'question_with_chunk.csv'.\n"
     ]
    }
   ],
   "source": [
    "# --- Bước 7: Thêm Cột \"Chunk\" vào Dữ Liệu Gốc ---\n",
    "\n",
    "# Khởi tạo cột 'Chunk' trong sentences_df\n",
    "sentences_df['Chunk'] = None\n",
    "\n",
    "# Duyệt qua từng chunk và gán cho các câu thuộc chunk đó\n",
    "for idx, row in chunks_df.iterrows():\n",
    "    chunk_text = row['Chunk']\n",
    "    # Sử dụng NLTK để phân tách các câu trong chunk\n",
    "    chunk_sentences = nltk.sent_tokenize(chunk_text)\n",
    "    \n",
    "    for sent in chunk_sentences:\n",
    "        # Tìm chỉ số của câu trong sentences_df\n",
    "        match_idx = sentences_df[sentences_df['Câu hỏi'] == sent].index\n",
    "        if not match_idx.empty:\n",
    "            sentences_df.at[match_idx[0], 'Chunk'] = chunk_text\n",
    "        else:\n",
    "            print(f\"Warning: Sentence '{sent}' not found in sentences_df.\")\n",
    "\n",
    "# Kiểm tra các chunk đã được gán\n",
    "print(\"\\nDữ liệu với cột 'Chunk':\")\n",
    "print(sentences_df)\n",
    "\n",
    "# Lưu DataFrame sentences_df vào file CSV\n",
    "output_filename = 'question_with_chunk.csv'\n",
    "sentences_df.to_csv(output_filename, index=False, encoding='utf-8-sig')\n",
    "\n",
    "print(f\"\\nDữ liệu đã được lưu vào file '{output_filename}'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Câu hỏi</th>\n",
       "      <th>Câu trả lời</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Các quả có mùi vị như thế nào?</td>\n",
       "      <td>Quả cam ngon. Quả táo dở. Quả chanh chua. Quả ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Các quả có hình dáng như thế nào?</td>\n",
       "      <td>Quả cam có hình tròn. Quả táo có hình tròn, hơ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Câu hỏi  \\\n",
       "0     Các quả có mùi vị như thế nào?   \n",
       "1  Các quả có hình dáng như thế nào?   \n",
       "\n",
       "                                         Câu trả lời  \n",
       "0  Quả cam ngon. Quả táo dở. Quả chanh chua. Quả ...  \n",
       "1  Quả cam có hình tròn. Quả táo có hình tròn, hơ...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Câu hỏi</th>\n",
       "      <th>Chunk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Các quả có mùi vị như thế nào?</td>\n",
       "      <td>Các quả có mùi vị như thế nào? Các quả có hình...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Các quả có hình dáng như thế nào?</td>\n",
       "      <td>Các quả có mùi vị như thế nào? Các quả có hình...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Câu hỏi  \\\n",
       "0     Các quả có mùi vị như thế nào?   \n",
       "1  Các quả có hình dáng như thế nào?   \n",
       "\n",
       "                                               Chunk  \n",
       "0  Các quả có mùi vị như thế nào? Các quả có hình...  \n",
       "1  Các quả có mùi vị như thế nào? Các quả có hình...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dữ liệu đã được ghép và lưu vào file 'test_data_with_chunk.csv'.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Tạo danh sách để lưu kết quả\n",
    "expanded_rows = []\n",
    "\n",
    "# Duyệt qua từng dòng trong data\n",
    "for _, data_row in data.iterrows():\n",
    "    question = data_row['Câu hỏi']  # Câu hỏi từ data\n",
    "    full_answer = data_row['Câu trả lời']  # Câu trả lời từ data\n",
    "\n",
    "    # Tìm các chunk tương ứng từ sentences_df\n",
    "    matching_chunks = sentences_df[sentences_df['Câu hỏi'] == question]\n",
    "    if not matching_chunks.empty:\n",
    "        for _, chunk_row in matching_chunks.iterrows():\n",
    "            chunk = chunk_row['Chunk']  # Lấy giá trị Chunk\n",
    "            expanded_rows.append({\n",
    "                'Câu hỏi': question,\n",
    "                'Câu trả lời': full_answer,\n",
    "                'Chunk': chunk\n",
    "            })\n",
    "\n",
    "# Tạo DataFrame từ danh sách kết quả\n",
    "test_data_with_chunk = pd.DataFrame(expanded_rows)\n",
    "\n",
    "# Lưu kết quả vào file CSV\n",
    "output_file = 'test_data_with_chunk.csv'\n",
    "test_data_with_chunk.to_csv(output_file, index=False, encoding='utf-8-sig')\n",
    "\n",
    "print(f\"Dữ liệu đã được ghép và lưu vào file '{output_file}'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChromaDB client initialized successfully.\n",
      "Collection 'my_collection1' created or retrieved successfully.\n",
      "Model 'keepitreal/vietnamese-sbert' loaded successfully.\n",
      "DataFrame loaded with 2 rows.\n",
      "Data divided into 1 batches.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf68c8493484409bbee95251a08f0448",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully added 2 items to the collection.\n",
      "Number of elements in collection: 2\n",
      "Metadata 1: {'Chunk': 'Các quả có mùi vị như thế nào? Các quả có hình dáng như thế nào?', 'Câu hỏi': 'Các quả có mùi vị như thế nào?', 'Câu trả lời': 'Quả cam ngon. Quả táo dở. Quả chanh chua. Quả mít to. Quả mít rất thơm nữa.'}\n",
      "Metadata 2: {'Chunk': 'Các quả có mùi vị như thế nào? Các quả có hình dáng như thế nào?', 'Câu hỏi': 'Các quả có hình dáng như thế nào?', 'Câu trả lời': 'Quả cam có hình tròn. Quả táo có hình tròn, hơi nhỏ. Quả chanh hình bầu dục. Quả mít to dài có vỏ xù xì. Quả mít có thể lấy gỗ.'}\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import uuid\n",
    "import pandas as pd\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import chromadb\n",
    "\n",
    "# --- Initialize ChromaDB Client ---\n",
    "try:\n",
    "    chroma_client = chromadb.PersistentClient(path=\"./chroma_db\")  # Updated client configuration\n",
    "    print(\"ChromaDB client initialized successfully.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error initializing ChromaDB client: {e}\")\n",
    "    exit()\n",
    "\n",
    "# --- Create or Retrieve Collection ---\n",
    "collection_name = \"my_collection1\"\n",
    "try:\n",
    "    collection = chroma_client.get_or_create_collection(name=collection_name)\n",
    "    print(f\"Collection '{collection_name}' created or retrieved successfully.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error creating or retrieving collection: {e}\")\n",
    "    collection = None  # Ensure collection is None if creation fails\n",
    "\n",
    "if collection is None:\n",
    "    print(\"Collection is not available. Exiting.\")\n",
    "    exit()\n",
    "\n",
    "# --- Load SentenceTransformer Model ---\n",
    "model_name = \"keepitreal/vietnamese-sbert\"\n",
    "try:\n",
    "    model = SentenceTransformer(model_name)\n",
    "    print(f\"Model '{model_name}' loaded successfully.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading model '{model_name}': {e}\")\n",
    "    exit()\n",
    "\n",
    "\n",
    "# --- Load Actual Data ---\n",
    "try:\n",
    "    # Replace this part with your actual data\n",
    "    test_data_with_chunk = pd.DataFrame({\n",
    "        'Câu hỏi': [\n",
    "            \"Các quả có mùi vị như thế nào?\",\n",
    "            \"Các quả có hình dáng như thế nào?\"\n",
    "        ],\n",
    "        'Câu trả lời': [\n",
    "            \"Quả cam ngon. Quả táo dở. Quả chanh chua. Quả mít to. Quả mít rất thơm nữa.\",\n",
    "            \"Quả cam có hình tròn. Quả táo có hình tròn, hơi nhỏ. Quả chanh hình bầu dục. Quả mít to dài có vỏ xù xì. Quả mít có thể lấy gỗ.\"\n",
    "        ],\n",
    "        'Chunk': [\n",
    "            \"Các quả có mùi vị như thế nào? Các quả có hình dáng như thế nào?\",\n",
    "            \"Các quả có mùi vị như thế nào? Các quả có hình dáng như thế nào?\"\n",
    "        ]\n",
    "    })\n",
    "    print(f\"DataFrame loaded with {len(data)} rows.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading DataFrame: {e}\")\n",
    "    exit()\n",
    "\n",
    "\n",
    "# --- Function to Divide DataFrame into Batches ---\n",
    "def divide_dataframe(dataframe, batch_size):\n",
    "    \"\"\"Divide DataFrame into smaller batches.\"\"\"\n",
    "    num_batches = math.ceil(len(dataframe) / batch_size)\n",
    "    return [dataframe.iloc[i * batch_size:(i + 1) * batch_size] for i in range(num_batches)]\n",
    "\n",
    "# --- Function to Process Each Batch ---\n",
    "def process_batch(batch_df, model, collection):\n",
    "    \"\"\"Process and add data to ChromaDB collection.\"\"\"\n",
    "    try:\n",
    "        if 'Chunk' not in batch_df.columns:\n",
    "            raise ValueError(\"Column 'Chunk' not found in DataFrame.\")\n",
    "\n",
    "        embeddings = model.encode(batch_df['Chunk'].tolist(), show_progress_bar=True)\n",
    "        metadatas = batch_df.to_dict(orient='records')\n",
    "        batch_ids = [str(uuid.uuid4()) for _ in range(len(batch_df))]\n",
    "\n",
    "        collection.add(\n",
    "            ids=batch_ids,\n",
    "            embeddings=embeddings,\n",
    "            metadatas=metadatas\n",
    "        )\n",
    "        print(f\"Successfully added {len(batch_df)} items to the collection.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing batch: {e}\")\n",
    "\n",
    "# --- Process Data in Batches ---\n",
    "batch_size = 16\n",
    "df_batches = divide_dataframe(test_data_with_chunk, batch_size)\n",
    "print(f\"Data divided into {len(df_batches)} batches.\")\n",
    "\n",
    "try:\n",
    "    for batch_df in df_batches:\n",
    "        if not batch_df.empty:\n",
    "            process_batch(batch_df, model, collection)\n",
    "except Exception as e:\n",
    "    print(f\"Error processing batches: {e}\")\n",
    "\n",
    "# --- Fetch and Verify Data from Collection ---\n",
    "try:\n",
    "    result = collection.get(include=[\"metadatas\", \"embeddings\"])\n",
    "    if result and 'metadatas' in result:\n",
    "        print(f\"Number of elements in collection: {len(result['metadatas'])}\")\n",
    "        for i in range(min(5, len(result['metadatas']))):  # Display up to 5 items\n",
    "            print(f\"Metadata {i + 1}: {result['metadatas'][i]}\")\n",
    "    else:\n",
    "        print(\"No data found in the collection.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error fetching data from collection: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Number of requested results 5 is greater than number of elements in index 2, updating n_results = 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Search Results for: 'quả mít có vị gì'\n",
      "\n",
      "Result 1:\n",
      "Chunk: Các quả có mùi vị như thế nào? Các quả có hình dáng như thế nào?\n",
      "Câu hỏi: Các quả có mùi vị như thế nào?\n",
      "Câu trả lời: Quả cam ngon. Quả táo dở. Quả chanh chua. Quả mít to. Quả mít rất thơm nữa.\n",
      "Distance: 66.60543428586415\n",
      "\n",
      "Result 2:\n",
      "Chunk: Các quả có mùi vị như thế nào? Các quả có hình dáng như thế nào?\n",
      "Câu hỏi: Các quả có hình dáng như thế nào?\n",
      "Câu trả lời: Quả cam có hình tròn. Quả táo có hình tròn, hơi nhỏ. Quả chanh hình bầu dục. Quả mít to dài có vỏ xù xì. Quả mít có thể lấy gỗ.\n",
      "Distance: 66.60543428586415\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def vector_search(prompt, model, collection, top_k=5):\n",
    "    \"\"\"\n",
    "    Perform vector search in ChromaDB collection.\n",
    "    Args:\n",
    "        prompt (str): The search query.\n",
    "        model (SentenceTransformer): The loaded model for embedding.\n",
    "        collection: The ChromaDB collection object.\n",
    "        top_k (int): Number of top results to retrieve.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Encode the prompt into an embedding\n",
    "        prompt_embedding = model.encode([prompt], show_progress_bar=False)[0]\n",
    "        \n",
    "        # Perform the search in the collection\n",
    "        search_results = collection.query(\n",
    "            query_embeddings=[prompt_embedding],\n",
    "            n_results=top_k,\n",
    "            include=[\"metadatas\", \"distances\"]\n",
    "        )\n",
    "        \n",
    "        # Display the search results\n",
    "        if search_results and 'metadatas' in search_results:\n",
    "            print(f\"\\nSearch Results for: '{prompt}'\")\n",
    "            for i, metadata in enumerate(search_results['metadatas'][0]):\n",
    "                distance = search_results['distances'][0][i]\n",
    "                print(f\"\\nResult {i + 1}:\")\n",
    "                print(f\"Chunk: {metadata.get('Chunk')}\")\n",
    "                print(f\"Câu hỏi: {metadata.get('Câu hỏi')}\")\n",
    "                print(f\"Câu trả lời: {metadata.get('Câu trả lời')}\")\n",
    "                print(f\"Distance: {distance}\")\n",
    "        else:\n",
    "            print(f\"No results found for query: '{prompt}'\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error during vector search: {e}\")\n",
    "\n",
    "\n",
    "# --- Perform Vector Search ---\n",
    "prompt = \"quả mít có vị gì\"\n",
    "vector_search(prompt, model, collection, top_k=5)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
