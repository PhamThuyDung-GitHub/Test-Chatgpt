{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: C:\\Users\\ungdu\\Downloads\\Test Chatgpt\\Test data.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Câu hỏi</th>\n",
       "      <th>Câu trả lời</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Các quả có mùi vị như thế nào</td>\n",
       "      <td>Quả cam ngon. Quả táo dở. Quả chanh chua. Quả ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Các quả có hình dáng như thế nào</td>\n",
       "      <td>Quả cam có hình tròn. Quả táo có hình tròn, hơ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Câu hỏi  \\\n",
       "0      Các quả có mùi vị như thế nào   \n",
       "1  Các quả có hình dáng như thế nào    \n",
       "\n",
       "                                         Câu trả lời  \n",
       "0  Quả cam ngon. Quả táo dở. Quả chanh chua. Quả ...  \n",
       "1  Quả cam có hình tròn. Quả táo có hình tròn, hơ...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Function to handle file upload and data reading\n",
    "def upload_and_process_files(uploaded_files):\n",
    "    \"\"\"\n",
    "    Function to upload and process the CSV files.\n",
    "    \n",
    "    Args:\n",
    "    uploaded_files (list): List of file paths.\n",
    "    \n",
    "    Returns:\n",
    "    pd.DataFrame: Combined DataFrame from all uploaded CSV files.\n",
    "    \"\"\"\n",
    "    all_data = []  # List to store DataFrames from uploaded files\n",
    "    for file_path in uploaded_files:\n",
    "        print(f\"Processing file: {file_path}\")\n",
    "        if file_path.endswith(\".csv\"):\n",
    "            try:\n",
    "                # Try to read the CSV file with utf-8 encoding\n",
    "                df = pd.read_csv(file_path, encoding='utf-8')\n",
    "                # Clean column names by stripping spaces\n",
    "                df.columns = df.columns.str.strip()\n",
    "                all_data.append(df)\n",
    "            except pd.errors.ParserError:\n",
    "                raise ValueError(f\"Error: The file {file_path} is not in the correct format of a .csv file.\")\n",
    "    \n",
    "    # Combine all DataFrames into one\n",
    "    if all_data:\n",
    "        df_combined = pd.concat(all_data, ignore_index=True)\n",
    "        return df_combined\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "# Replace with actual file paths\n",
    "uploaded_files = [r'C:\\Users\\ungdu\\Downloads\\Test Chatgpt\\Test data.csv']  # Provide full file path(s)\n",
    "\n",
    "# Upload and process the file\n",
    "df_combined = upload_and_process_files(uploaded_files)\n",
    "\n",
    "# Display the first few rows to verify the data\n",
    "if df_combined is not None:\n",
    "    display(df_combined)\n",
    "else:\n",
    "    print(\"No data to display.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Câu hỏi: Các quả có mùi vị như thế nào\n",
      "Chunks:\n",
      "  Chunk 1: Quả cam ngon.\n",
      "  Chunk 2: Quả táo dở.\n",
      "  Chunk 3: Quả chanh chua.\n",
      "  Chunk 4: Quả mít to. Quả mít rất thơm nữa\n",
      "\n",
      "Câu hỏi: Các quả có hình dáng như thế nào \n",
      "Chunks:\n",
      "  Chunk 1: Quả cam có hình tròn. Quả táo có hình tròn, hơi nhỏ.\n",
      "  Chunk 2: Quả chanh hình bầu dục.\n",
      "  Chunk 3: Quả mít to dài có vỏ xù xì.\n",
      "  Chunk 4: Quả mít có thể lấy gỗ\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Ensure that punkt is downloaded for sentence tokenization\n",
    "nltk.download(\"punkt\", quiet=True)\n",
    "\n",
    "# Define the chunking class\n",
    "class SemanticChunker:\n",
    "    def __init__(self, threshold=0.3, embedding_type=\"tfidf\"):\n",
    "        self.threshold = threshold\n",
    "        self.embedding_type = embedding_type\n",
    "    \n",
    "    def embed_function(self, sentences):\n",
    "        \"\"\"\n",
    "        Convert a list of sentences into their vector representations using TF-IDF.\n",
    "        \n",
    "        Args:\n",
    "        - sentences (list): List of sentences to be embedded.\n",
    "        \n",
    "        Returns:\n",
    "        - numpy.ndarray: The TF-IDF vectors.\n",
    "        \"\"\"\n",
    "        if self.embedding_type == \"tfidf\":\n",
    "            vectorizer = TfidfVectorizer().fit_transform(sentences)\n",
    "            return vectorizer.toarray()\n",
    "        else:\n",
    "            raise ValueError(\"Unsupported embedding type\")\n",
    "    \n",
    "    def split_text(self, text):\n",
    "        \"\"\"\n",
    "        Split the input text into chunks based on semantic similarity of sentences.\n",
    "        \n",
    "        Args:\n",
    "        - text (str): Input text to be chunked.\n",
    "        \n",
    "        Returns:\n",
    "        - list: List of chunked text.\n",
    "        \"\"\"\n",
    "        sentences = nltk.sent_tokenize(text)  # Extract sentences\n",
    "        sentences = [item for item in sentences if item and item.strip()]\n",
    "        if not len(sentences):\n",
    "            return []\n",
    "\n",
    "        # Vectorize the sentences for similarity checking\n",
    "        vectors = self.embed_function(sentences)\n",
    "\n",
    "        # Calculate pairwise cosine similarity between sentences\n",
    "        similarities = cosine_similarity(vectors)\n",
    "\n",
    "        # Initialize chunks with the first sentence\n",
    "        chunks = [[sentences[0]]]\n",
    "\n",
    "        # Group sentences into chunks based on similarity threshold\n",
    "        for i in range(1, len(sentences)):\n",
    "            sim_score = similarities[i-1, i]\n",
    "\n",
    "            if sim_score >= self.threshold:\n",
    "                # If the similarity is above the threshold, add to the current chunk\n",
    "                chunks[-1].append(sentences[i])\n",
    "            else:\n",
    "                # Start a new chunk\n",
    "                chunks.append([sentences[i]])\n",
    "\n",
    "        # Join the sentences in each chunk to form coherent paragraphs\n",
    "        return [' '.join(chunk) for chunk in chunks]\n",
    "\n",
    "# Initialize the SemanticChunker (adjust threshold if needed)\n",
    "chunker = SemanticChunker(threshold=0.3)\n",
    "\n",
    "# Apply the chunking process to the \"Câu trả lời\" column\n",
    "df_combined[\"Chunks\"] = df_combined[\"Câu trả lời\"].apply(lambda x: chunker.split_text(x))\n",
    "\n",
    "# Display the chunked results\n",
    "for index, row in df_combined.iterrows():\n",
    "    print(f\"\\nCâu hỏi: {row['Câu hỏi']}\")\n",
    "    print(\"Chunks:\")\n",
    "    for i, chunk in enumerate(row[\"Chunks\"]):\n",
    "        print(f\"  Chunk {i+1}: {chunk}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data has been successfully exported to chunking_data.csv\n"
     ]
    }
   ],
   "source": [
    "# Export the DataFrame with chunked data to a CSV file\n",
    "df_combined.to_csv('chunking_data.csv', index=False, encoding='utf-8')\n",
    "\n",
    "print(\"Data has been successfully exported to chunking_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ungdu\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sentence_transformers\\cross_encoder\\CrossEncoder.py:11: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm, trange\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                             Câu hỏi  \\\n",
      "0      Các quả có mùi vị như thế nào   \n",
      "1  Các quả có hình dáng như thế nào    \n",
      "\n",
      "                                         Câu trả lời  \\\n",
      "0  Quả cam ngon. Quả táo dở. Quả chanh chua. Quả ...   \n",
      "1  Quả cam có hình tròn. Quả táo có hình tròn, hơ...   \n",
      "\n",
      "                                              Chunks  \\\n",
      "0  [Quả cam ngon., Quả táo dở., Quả chanh chua., ...   \n",
      "1  [Quả cam có hình tròn. Quả táo có hình tròn, h...   \n",
      "\n",
      "                                          Embeddings  \n",
      "0  [[tensor(0.3438), tensor(0.4892), tensor(0.466...  \n",
      "1  [[tensor(0.0007), tensor(-0.0319), tensor(0.32...  \n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "import numpy as np\n",
    "\n",
    "# Initialize the Vietnamese SBERT model\n",
    "embedding_model = SentenceTransformer('keepitreal/vietnamese-sbert')\n",
    "\n",
    "# Function to embed text using the pre-trained model\n",
    "def embed_text(text_list):\n",
    "    \"\"\"\n",
    "    Function to embed a list of texts using the pre-trained Vietnamese SBERT model.\n",
    "\n",
    "    Args:\n",
    "    text_list (list): List of text sentences to be embedded.\n",
    "\n",
    "    Returns:\n",
    "    np.ndarray: Embeddings for each sentence.\n",
    "    \"\"\"\n",
    "    embeddings = embedding_model.encode(text_list, convert_to_tensor=True)\n",
    "    return embeddings\n",
    "\n",
    "# Example: Apply embedding model to chunked text\n",
    "def apply_embeddings_to_chunks(df):\n",
    "    \"\"\"\n",
    "    Function to apply embeddings to the chunked texts.\n",
    "\n",
    "    Args:\n",
    "    df (pd.DataFrame): DataFrame containing chunked texts.\n",
    "\n",
    "    Returns:\n",
    "    pd.DataFrame: DataFrame with embeddings added.\n",
    "    \"\"\"\n",
    "    # Loop through each row in the DataFrame and apply embedding to each chunk\n",
    "    embeddings_list = []\n",
    "    for index, row in df.iterrows():\n",
    "        question = row['Câu hỏi']\n",
    "        chunks = row['Chunks']\n",
    "        \n",
    "        # Embed the chunks using the Vietnamese SBERT model\n",
    "        embeddings = embed_text(chunks)\n",
    "        \n",
    "        # Store the embeddings in a list\n",
    "        embeddings_list.append(embeddings)\n",
    "        \n",
    "    # Add embeddings to the DataFrame\n",
    "    df['Embeddings'] = embeddings_list\n",
    "    return df\n",
    "\n",
    "# Apply the embedding model to the chunked text data\n",
    "df_with_embeddings = apply_embeddings_to_chunks(df_combined)\n",
    "\n",
    "# Display the resulting DataFrame with embeddings\n",
    "print(df_with_embeddings.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data with embeddings has been successfully exported to embedding_data.csv\n"
     ]
    }
   ],
   "source": [
    "# Convert the embeddings into a string format to store in CSV\n",
    "df_with_embeddings['Embeddings'] = df_with_embeddings['Embeddings'].apply(lambda x: str(x.tolist()))\n",
    "\n",
    "# Export the DataFrame with embeddings to a CSV file\n",
    "df_with_embeddings.to_csv('embedding_data.csv', index=False, encoding='utf-8')\n",
    "\n",
    "print(\"Data with embeddings has been successfully exported to embedding_data.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
