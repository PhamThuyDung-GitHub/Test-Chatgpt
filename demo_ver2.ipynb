{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EXPLAIN & TEST FLOWCHART "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to handle file upload and data reading\n",
    "def upload_and_process_files(uploaded_files):\n",
    "    \"\"\"\n",
    "    Function to upload and process the CSV files.\n",
    "\n",
    "    Args:\n",
    "    uploaded_files (list): List of file paths.\n",
    "\n",
    "    Returns:\n",
    "    pd.DataFrame: Combined DataFrame from all uploaded CSV files.\n",
    "    \"\"\"\n",
    "    for file_path in uploaded_files:\n",
    "        print(f\"Processing file: {file_path}\")\n",
    "        if file_path.endswith(\".csv\"):\n",
    "            try:\n",
    "                # Try to read the CSV file\n",
    "                df = pd.read_csv(file_path)\n",
    "                all_data.append(df)\n",
    "            except pd.errors.ParserError:\n",
    "                # Handle CSV parsing error\n",
    "                raise ValueError(f\"Error: The file {file_path} is not in the correct format of a .csv file.\")\n",
    "    \n",
    "    if all_data:\n",
    "        # Combine all DataFrames into one\n",
    "        df_combined = pd.concat(all_data, ignore_index=True)\n",
    "        return df_combined\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: C:\\Users\\ungdu\\Downloads\\Test Chatgpt\\Test data.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Câu hỏi</th>\n",
       "      <th>Câu trả lời</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Các quả có mùi vị như thế nào</td>\n",
       "      <td>Quả cam ngon. Quả táo dở. Quả chanh chua. Quả ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Các quả có hình dáng như thế nào</td>\n",
       "      <td>Quả cam có hình tròn. Quả táo có hình tròn, hơ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Câu hỏi   \\\n",
       "0      Các quả có mùi vị như thế nào   \n",
       "1  Các quả có hình dáng như thế nào    \n",
       "\n",
       "                                         Câu trả lời  \n",
       "0  Quả cam ngon. Quả táo dở. Quả chanh chua. Quả ...  \n",
       "1  Quả cam có hình tròn. Quả táo có hình tròn, hơ...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Replace with actual file paths\n",
    "uploaded_files = [r'C:\\Users\\ungdu\\Downloads\\Test Chatgpt\\Test data.csv']  # Provide full file path(s)\n",
    "\n",
    "df_combined = upload_and_process_files(uploaded_files)\n",
    "\n",
    "if df_combined is not None:\n",
    "    # Display the DataFrame in Jupyter notebook\n",
    "    display(df_combined)\n",
    "else:\n",
    "    print(\"No data to display.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                             Câu hỏi  \\\n",
      "0      Các quả có mùi vị như thế nào   \n",
      "1  Các quả có hình dáng như thế nào    \n",
      "\n",
      "                                         Câu trả lời  \\\n",
      "0  Quả cam ngon. Quả táo dở. Quả chanh chua. Quả ...   \n",
      "1  Quả cam có hình tròn. Quả táo có hình tròn, hơ...   \n",
      "\n",
      "                                              Chunks  \n",
      "0  [Quả cam ngon., Quả táo dở., Quả chanh chua., ...  \n",
      "1  [Quả cam có hình tròn. Quả táo có hình tròn, h...  \n"
     ]
    }
   ],
   "source": [
    "print(df_combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Câu hỏi ', 'Câu trả lời', 'Chunks'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Display the column names to check for any discrepancies\n",
    "print(df_combined.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Câu hỏi', 'Câu trả lời', 'Chunks'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Strip any extra spaces from the column names\n",
    "df_combined.columns = df_combined.columns.str.strip()\n",
    "\n",
    "# Print the columns again to check\n",
    "print(df_combined.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Câu hỏi: Các quả có mùi vị như thế nào\n",
      "Chunks:\n",
      "  Chunk 1: Quả cam ngon.\n",
      "  Chunk 2: Quả táo dở.\n",
      "  Chunk 3: Quả chanh chua.\n",
      "  Chunk 4: Quả mít to. Quả mít rất thơm nữa\n",
      "\n",
      "Câu hỏi: Các quả có hình dáng như thế nào \n",
      "Chunks:\n",
      "  Chunk 1: Quả cam có hình tròn. Quả táo có hình tròn, hơi nhỏ.\n",
      "  Chunk 2: Quả chanh hình bầu dục.\n",
      "  Chunk 3: Quả mít to dài có vỏ xù xì.\n",
      "  Chunk 4: Quả mít có thể lấy gỗ\n"
     ]
    }
   ],
   "source": [
    "# Apply the chunking process to the \"Câu trả lời\" column\n",
    "df_combined[\"Chunks\"] = df_combined[\"Câu trả lời\"].apply(lambda x: chunker.split_text(x))\n",
    "\n",
    "# Display the chunked results\n",
    "for index, row in df_combined.iterrows():\n",
    "    # Make sure that the column names match exactly\n",
    "    print(f\"\\nCâu hỏi: {row['Câu hỏi']}\")\n",
    "    print(\"Chunks:\")\n",
    "    for i, chunk in enumerate(row[\"Chunks\"]):\n",
    "        print(f\"  Chunk {i+1}: {chunk}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(file_path, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CHUNKING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: C:\\Users\\ungdu\\Downloads\\Test Chatgpt\\Test data.csv\n",
      "                             Câu hỏi  \\\n",
      "0      Các quả có mùi vị như thế nào   \n",
      "1  Các quả có hình dáng như thế nào    \n",
      "\n",
      "                                         Câu trả lời  \n",
      "0  Quả cam ngon. Quả táo dở. Quả chanh chua. Quả ...  \n",
      "1  Quả cam có hình tròn. Quả táo có hình tròn, hơ...  \n",
      "\n",
      "Câu hỏi: Các quả có mùi vị như thế nào\n",
      "Chunks:\n",
      "  Chunk 1: Quả cam ngon.\n",
      "  Chunk 2: Quả táo dở.\n",
      "  Chunk 3: Quả chanh chua.\n",
      "  Chunk 4: Quả mít to. Quả mít rất thơm nữa\n",
      "\n",
      "Câu hỏi: Các quả có hình dáng như thế nào \n",
      "Chunks:\n",
      "  Chunk 1: Quả cam có hình tròn. Quả táo có hình tròn, hơi nhỏ.\n",
      "  Chunk 2: Quả chanh hình bầu dục.\n",
      "  Chunk 3: Quả mít to dài có vỏ xù xì.\n",
      "  Chunk 4: Quả mít có thể lấy gỗ\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Ensure that punkt is downloaded for sentence tokenization\n",
    "nltk.download(\"punkt\", quiet=True)\n",
    "\n",
    "class SemanticChunker:\n",
    "    def __init__(self, threshold=0.3, embedding_type=\"tfidf\"):\n",
    "        self.threshold = threshold\n",
    "        self.embedding_type = embedding_type\n",
    "    \n",
    "    def embed_function(self, sentences):\n",
    "        if self.embedding_type == \"tfidf\":\n",
    "            vectorizer = TfidfVectorizer().fit_transform(sentences)\n",
    "            return vectorizer.toarray()\n",
    "        else:\n",
    "            raise ValueError(\"Unsupported embedding type\")\n",
    "    \n",
    "    def split_text(self, text):\n",
    "        sentences = nltk.sent_tokenize(text)\n",
    "        sentences = [item for item in sentences if item and item.strip()]\n",
    "        if not len(sentences):\n",
    "            return []\n",
    "        vectors = self.embed_function(sentences)\n",
    "        similarities = cosine_similarity(vectors)\n",
    "        chunks = [[sentences[0]]]\n",
    "        for i in range(1, len(sentences)):\n",
    "            sim_score = similarities[i-1, i]\n",
    "            if sim_score >= self.threshold:\n",
    "                chunks[-1].append(sentences[i])\n",
    "            else:\n",
    "                chunks.append([sentences[i]])\n",
    "        return [' '.join(chunk) for chunk in chunks]\n",
    "\n",
    "# Function to handle file upload and data reading\n",
    "def upload_and_process_files(uploaded_files):\n",
    "    all_data = []\n",
    "    for file_path in uploaded_files:\n",
    "        print(f\"Processing file: {file_path}\")\n",
    "        if file_path.endswith(\".csv\"):\n",
    "            try:\n",
    "                df = pd.read_csv(file_path, encoding='utf-8')  # Ensure proper encoding\n",
    "                df.columns = df.columns.str.strip()  # Strip extra spaces from column names\n",
    "                all_data.append(df)\n",
    "            except pd.errors.ParserError:\n",
    "                raise ValueError(f\"Error: The file {file_path} is not in the correct format of a .csv file.\")\n",
    "    if all_data:\n",
    "        df_combined = pd.concat(all_data, ignore_index=True)\n",
    "        return df_combined\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "# Replace with actual file paths\n",
    "uploaded_files = [r'C:\\Users\\ungdu\\Downloads\\Test Chatgpt\\Test data.csv']  # Provide full file path(s)\n",
    "\n",
    "# Upload and process the file\n",
    "df_combined = upload_and_process_files(uploaded_files)\n",
    "\n",
    "if df_combined is not None:\n",
    "    # Display the DataFrame in Jupyter notebook\n",
    "    print(df_combined.head())  # Check the first few rows\n",
    "\n",
    "    # Initialize the SemanticChunker\n",
    "    chunker = SemanticChunker(threshold=0.3)\n",
    "\n",
    "    # Apply the chunking process to the \"Câu trả lời\" column\n",
    "    df_combined[\"Chunks\"] = df_combined[\"Câu trả lời\"].apply(lambda x: chunker.split_text(x))\n",
    "\n",
    "    # Display the chunked results\n",
    "    for index, row in df_combined.iterrows():\n",
    "        print(f\"\\nCâu hỏi: {row['Câu hỏi']}\")\n",
    "        print(\"Chunks:\")\n",
    "        for i, chunk in enumerate(row[\"Chunks\"]):\n",
    "            print(f\"  Chunk {i+1}: {chunk}\")\n",
    "else:\n",
    "    print(\"No data to display.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
