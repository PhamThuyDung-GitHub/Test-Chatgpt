{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ungdu\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sentence_transformers\\cross_encoder\\CrossEncoder.py:11: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm, trange\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import chromadb\n",
    "from chromadb.config import Settings\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import numpy as np\n",
    "nltk.download(\"punkt\", quiet=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Câu hỏi</th>\n",
       "      <th>Câu trả lời</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Các quả có mùi vị như thế nào?</td>\n",
       "      <td>Quả cam ngon. Quả táo dở. Quả chanh chua. Quả ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Các quả có hình dáng như thế nào?</td>\n",
       "      <td>Quả cam có hình tròn. Quả táo có hình tròn, hơ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Câu hỏi  \\\n",
       "0     Các quả có mùi vị như thế nào?   \n",
       "1  Các quả có hình dáng như thế nào?   \n",
       "\n",
       "                                         Câu trả lời  \n",
       "0  Quả cam ngon. Quả táo dở. Quả chanh chua. Quả ...  \n",
       "1  Quả cam có hình tròn. Quả táo có hình tròn, hơ...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path = r'C:\\Users\\ungdu\\Downloads\\Test_Chatgpt\\test_data.csv' #import data\n",
    "data = pd.read_csv(file_path)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\ungdu\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Quả cam ngon.',\n",
       " 'Quả táo dở.',\n",
       " 'Quả chanh chua.',\n",
       " 'Quả mít to.',\n",
       " 'Quả mít rất thơm nữa.']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "['Quả cam có hình tròn.',\n",
       " 'Quả táo có hình tròn, hơi nhỏ.',\n",
       " 'Quả chanh hình bầu dục.',\n",
       " 'Quả mít to dài có vỏ xù xì.',\n",
       " 'Quả mít có thể lấy gỗ.']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from IPython.display import display\n",
    "\n",
    "# Tải bộ dữ liệu phân tách câu của NLTK nếu chưa có\n",
    "nltk.download('punkt')\n",
    "\n",
    "\n",
    "# Danh sách chứa tất cả các câu đã phân tách\n",
    "all_sentences = []\n",
    "\n",
    "# Lặp qua từng dòng của DataFrame\n",
    "for _, row in data.iterrows():\n",
    "    # Lấy nội dung cột \"Câu trả lời\"\n",
    "    text = row.get(\"Câu trả lời\", \"\")\n",
    "    \n",
    "    # Kiểm tra nếu text không rỗng và là chuỗi\n",
    "    if text and isinstance(text, str):\n",
    "        # Chia văn bản thành các câu\n",
    "        sentences = nltk.sent_tokenize(text)\n",
    "        \n",
    "        # Hiển thị từng câu đã tách (chỉ để kiểm tra)\n",
    "        display(sentences)\n",
    "        \n",
    "        # Thêm các câu này vào danh sách tổng hợp\n",
    "        all_sentences.extend(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Đã lưu 10 câu vào file 'extracted_sentences.csv'.\n"
     ]
    }
   ],
   "source": [
    "# Tạo DataFrame từ danh sách các câu\n",
    "sentences_df = pd.DataFrame({'Câu trả lời': all_sentences})\n",
    "\n",
    "# Lưu DataFrame vào file CSV\n",
    "output_filename = 'extracted_sentences.csv'\n",
    "sentences_df.to_csv(output_filename, index=False, encoding='utf-8-sig')\n",
    "\n",
    "print(f\"Đã lưu {len(all_sentences)} câu vào file '{output_filename}'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      Câu trả lời\n",
      "0                   Quả cam ngon.\n",
      "1                     Quả táo dở.\n",
      "2                 Quả chanh chua.\n",
      "3                     Quả mít to.\n",
      "4           Quả mít rất thơm nữa.\n",
      "5           Quả cam có hình tròn.\n",
      "6  Quả táo có hình tròn, hơi nhỏ.\n",
      "7         Quả chanh hình bầu dục.\n",
      "8     Quả mít to dài có vỏ xù xì.\n",
      "9          Quả mít có thể lấy gỗ.\n",
      "Đã tải 10 câu từ 'extracted_sentences.csv'.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Đọc file CSV chứa các câu đã được tách\n",
    "sentences_df = pd.read_csv('extracted_sentences.csv', encoding='utf-8-sig')\n",
    "print(sentences_df)\n",
    "# Hiển thị số lượng câu đã được tải\n",
    "print(f\"Đã tải {len(sentences_df)} câu từ 'extracted_sentences.csv'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ma trận TF-IDF có kích thước: (10, 26)\n",
      "Mẫu độ tương đồng giữa các câu:\n",
      "[[1.         0.07351663 0.07351663 0.08803749 0.0530266 ]\n",
      " [0.07351663 1.         0.07351663 0.08803749 0.0530266 ]\n",
      " [0.07351663 0.07351663 1.         0.08803749 0.0530266 ]\n",
      " [0.08803749 0.08803749 0.08803749 1.         0.26661112]\n",
      " [0.0530266  0.0530266  0.0530266  0.26661112 1.        ]]\n"
     ]
    }
   ],
   "source": [
    "# Bước 3: Vector hóa các câu sử dụng TF-IDF\n",
    "vectorizer = TfidfVectorizer()\n",
    "tfidf_matrix = vectorizer.fit_transform(sentences_df['Câu trả lời'])\n",
    "\n",
    "# Hiển thị kích thước ma trận TF-IDF\n",
    "print(f\"Ma trận TF-IDF có kích thước: {tfidf_matrix.shape}\")\n",
    "\n",
    "# Bước 2: Tính độ tương đồng giữa các câu bằng cosine similarity\n",
    "# Tính ma trận độ tương đồng giữa các câu\n",
    "cosine_sim = cosine_similarity(tfidf_matrix, tfidf_matrix)\n",
    "\n",
    "# Hiển thị một phần ma trận độ tương đồng\n",
    "print(\"Mẫu độ tương đồng giữa các câu:\")\n",
    "print(cosine_sim[:5, :5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Đã lưu ma trận TF-IDF vào file 'tfidf_matrix.csv'.\n"
     ]
    }
   ],
   "source": [
    "# 1. Lưu Ma Trận TF-IDF\n",
    "# Chuyển đổi ma trận TF-IDF thành DataFrame\n",
    "# Lưu ý: Nếu số lượng từ vựng (features) lớn, việc lưu trữ có thể tiêu tốn nhiều dung lượng\n",
    "tfidf_df = pd.DataFrame(tfidf_matrix.toarray(), columns=vectorizer.get_feature_names_out())\n",
    "\n",
    "# Lưu DataFrame TF-IDF vào CSV\n",
    "tfidf_output_filename = 'tfidf_matrix.csv'\n",
    "tfidf_df.to_csv(tfidf_output_filename, index=False, encoding='utf-8-sig')\n",
    "\n",
    "print(f\"Đã lưu ma trận TF-IDF vào file '{tfidf_output_filename}'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Đã lưu ma trận cosine similarity vào file 'cosine_similarity_matrix.csv'.\n"
     ]
    }
   ],
   "source": [
    "# 2. Lưu Ma Trận Cosine Similarity\n",
    "# Chuyển đổi ma trận cosine similarity thành DataFrame\n",
    "cosine_sim_df = pd.DataFrame(cosine_sim, index=sentences_df.index, columns=sentences_df.index)\n",
    "\n",
    "# Lưu DataFrame cosine similarity vào CSV\n",
    "cosine_sim_output_filename = 'cosine_similarity_matrix.csv'\n",
    "cosine_sim_df.to_csv(cosine_sim_output_filename, index=True, encoding='utf-8-sig')\n",
    "\n",
    "print(f\"Đã lưu ma trận cosine similarity vào file '{cosine_sim_output_filename}'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Độ tương đồng giữa câu 1 và câu 2: 0.07\n",
      "Độ tương đồng giữa câu 2 và câu 3: 0.07\n",
      "Độ tương đồng giữa câu 3 và câu 4: 0.09\n",
      "Độ tương đồng giữa câu 4 và câu 5: 0.27\n",
      "Độ tương đồng giữa câu 5 và câu 6: 0.05\n",
      "Độ tương đồng giữa câu 6 và câu 7: 0.54\n",
      "Độ tương đồng giữa câu 7 và câu 8: 0.17\n",
      "Độ tương đồng giữa câu 8 và câu 9: 0.03\n",
      "Độ tương đồng giữa câu 9 và câu 10: 0.21\n",
      "Đã lưu 9 chunks vào file 'chunked_sentences.csv'.\n"
     ]
    }
   ],
   "source": [
    "# Bước 4: Gép các câu lại với nhau dựa trên độ tương đồng\n",
    "\n",
    "# Thiết lập ngưỡng độ tương đồng\n",
    "SIMILARITY_THRESHOLD = 0.3  # Bạn có thể điều chỉnh ngưỡng này\n",
    "\n",
    "# Danh sách để lưu các chunk\n",
    "chunks = []\n",
    "current_chunk = sentences_df.iloc[0]['Câu trả lời']  # Bắt đầu với câu đầu tiên\n",
    "\n",
    "for i in range(1, len(sentences_df)):\n",
    "    prev_sentence = sentences_df.iloc[i - 1]['Câu trả lời']\n",
    "    current_sentence = sentences_df.iloc[i]['Câu trả lời']\n",
    "    \n",
    "    # Vector hóa câu hiện tại và câu trước đó\n",
    "    prev_vector = vectorizer.transform([prev_sentence])\n",
    "    current_vector = vectorizer.transform([current_sentence])\n",
    "    \n",
    "    # Tính độ tương đồng giữa câu trước và câu hiện tại\n",
    "    similarity = cosine_similarity(prev_vector, current_vector)[0][0]\n",
    "    \n",
    "    print(f\"Độ tương đồng giữa câu {i} và câu {i+1}: {similarity:.2f}\")\n",
    "    \n",
    "    if similarity >= SIMILARITY_THRESHOLD:\n",
    "        # Gép câu hiện tại vào chunk hiện tại\n",
    "        current_chunk += ' ' + current_sentence\n",
    "    else:\n",
    "        # Thêm chunk hiện tại vào danh sách và bắt đầu chunk mới\n",
    "        chunks.append(current_chunk)\n",
    "        current_chunk = current_sentence\n",
    "\n",
    "# Thêm chunk cuối cùng vào danh sách\n",
    "chunks.append(current_chunk)\n",
    "\n",
    "# Tạo DataFrame từ các chunk\n",
    "chunks_df = pd.DataFrame({'Chunk': chunks})\n",
    "\n",
    "# Lưu các chunk vào file CSV mới\n",
    "output_chunk_filename = 'chunked_sentences.csv'\n",
    "chunks_df.to_csv(output_chunk_filename, index=False, encoding='utf-8-sig')\n",
    "\n",
    "print(f\"Đã lưu {len(chunks)} chunks vào file '{output_chunk_filename}'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dữ liệu với cột 'Chunk':\n",
      "                      Câu trả lời  \\\n",
      "0                   Quả cam ngon.   \n",
      "1                     Quả táo dở.   \n",
      "2                 Quả chanh chua.   \n",
      "3                     Quả mít to.   \n",
      "4           Quả mít rất thơm nữa.   \n",
      "5           Quả cam có hình tròn.   \n",
      "6  Quả táo có hình tròn, hơi nhỏ.   \n",
      "7         Quả chanh hình bầu dục.   \n",
      "8     Quả mít to dài có vỏ xù xì.   \n",
      "9          Quả mít có thể lấy gỗ.   \n",
      "\n",
      "                                               Chunk  \n",
      "0                                      Quả cam ngon.  \n",
      "1                                        Quả táo dở.  \n",
      "2                                    Quả chanh chua.  \n",
      "3                                        Quả mít to.  \n",
      "4                              Quả mít rất thơm nữa.  \n",
      "5  Quả cam có hình tròn. Quả táo có hình tròn, hơ...  \n",
      "6  Quả cam có hình tròn. Quả táo có hình tròn, hơ...  \n",
      "7                            Quả chanh hình bầu dục.  \n",
      "8                        Quả mít to dài có vỏ xù xì.  \n",
      "9                             Quả mít có thể lấy gỗ.  \n",
      "\n",
      "Dữ liệu gốc sau khi thêm cột 'Chunk':\n",
      "                             Câu hỏi  \\\n",
      "0     Các quả có mùi vị như thế nào?   \n",
      "1  Các quả có hình dáng như thế nào?   \n",
      "\n",
      "                                         Câu trả lời Chunk  \n",
      "0  Quả cam ngon. Quả táo dở. Quả chanh chua. Quả ...   NaN  \n",
      "1  Quả cam có hình tròn. Quả táo có hình tròn, hơ...   NaN  \n",
      "\n",
      "Đã lưu dữ liệu với cột 'Chunk' vào file 'test_data_with_chunk.csv'.\n"
     ]
    }
   ],
   "source": [
    "# --- Bước 7: Thêm Cột \"Chunk\" vào Dữ Liệu Gốc ---\n",
    "\n",
    "# Khởi tạo cột 'Chunk' trong sentences_df\n",
    "sentences_df['Chunk'] = None\n",
    "\n",
    "# Duyệt qua từng chunk và gán cho các câu thuộc chunk đó\n",
    "for idx, row in chunks_df.iterrows():\n",
    "    chunk_text = row['Chunk']\n",
    "    # Sử dụng NLTK để phân tách các câu trong chunk\n",
    "    chunk_sentences = nltk.sent_tokenize(chunk_text)\n",
    "    \n",
    "    for sent in chunk_sentences:\n",
    "        # Tìm chỉ số của câu trong sentences_df\n",
    "        match_idx = sentences_df[sentences_df['Câu trả lời'] == sent].index\n",
    "        if not match_idx.empty:\n",
    "            sentences_df.at[match_idx[0], 'Chunk'] = chunk_text\n",
    "        else:\n",
    "            print(f\"Warning: Sentence '{sent}' not found in sentences_df.\")\n",
    "\n",
    "# Kiểm tra các chunk đã được gán\n",
    "print(\"\\nDữ liệu với cột 'Chunk':\")\n",
    "print(sentences_df)\n",
    "\n",
    "# --- Bước 8: Gộp Cột \"Chunk\" Vào Dữ Liệu Gốc ---\n",
    "# Merge dựa trên cột 'Câu trả lời'\n",
    "data_with_chunks = pd.merge(data, sentences_df[['Câu trả lời', 'Chunk']], on='Câu trả lời', how='left')\n",
    "\n",
    "# Hiển thị dữ liệu đã được gán 'Chunk'\n",
    "print(\"\\nDữ liệu gốc sau khi thêm cột 'Chunk':\")\n",
    "print(data_with_chunks)\n",
    "\n",
    "# --- Bước 9: Lưu Dữ Liệu Với Cột \"Chunk\" ---\n",
    "output_data_with_chunk = 'test_data_with_chunk.csv'\n",
    "data_with_chunks.to_csv(output_data_with_chunk, index=False, encoding='utf-8-sig')\n",
    "print(f\"\\nĐã lưu dữ liệu với cột 'Chunk' vào file '{output_data_with_chunk}'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def divide_dataframe(data_with_chunks, batch_size):\n",
    "    num_batches = math.ceil(len(data_with_chunks) / batch_size)  # Tính số lượng batch\n",
    "    return [data_with_chunks.iloc[i * batch_size:(i + 1) * batch_size] for i in range(num_batches)] # Định nghĩa khoảng cho từng batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "\n",
    "def process_batch(batch_df, model, collection):\n",
    "    \"\"\"Mã hóa và lưu dữ liệu vào Chroma vector store cho batch này.\"\"\"\n",
    "    try:\n",
    "        # Mã hóa dữ liệu trong cột 'chunk' thành vector cho batch này\n",
    "        embeddings = model.encode(batch_df['Chunk'].tolist())\n",
    "\n",
    "        # Thu thập tất cả metadata vào một danh sách\n",
    "        metadatas = [row.to_dict() for _, row in batch_df.iterrows()]\n",
    "\n",
    "        # Tạo ID duy nhất cho mỗi phần tử trong batch\n",
    "        batch_ids = [str(uuid.uuid4()) for _ in range(len(batch_df))]\n",
    "\n",
    "        # Thêm batch vào Chroma collection\n",
    "        collection.add(\n",
    "            ids=batch_ids,\n",
    "            embeddings=embeddings,\n",
    "            metadatas=metadatas\n",
    "        )\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Xảy ra lỗi khi thêm dữ liệu vào Chroma: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collection 'my_collection1' đã được tạo hoặc lấy thành công.\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import chromadb\n",
    "\n",
    "chroma_client = chromadb.Client()\n",
    "model = SentenceTransformer('keepitreal/vietnamese-sbert')\n",
    "batch_size = 16\n",
    "\n",
    "# Chia DataFrame thành các batch nhỏ\n",
    "df_batches = divide_dataframe(chunks_df, batch_size)\n",
    "\n",
    "# Kiểm tra nếu collection đã tồn tại hoặc tạo mới\n",
    "collection_name = \"my_collection1\"\n",
    "collection = chroma_client.get_or_create_collection(name=collection_name)\n",
    "\n",
    "# In ra thông tin collection để xác nhận\n",
    "print(f\"Collection '{collection_name}' đã được tạo hoặc lấy thành công.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Xử lý từng batch và thêm vào collection\n",
    "for i, batch_df in enumerate(df_batches):\n",
    "    if batch_df.empty:\n",
    "        continue  # Bỏ qua batch trống\n",
    "    process_batch(batch_df, model, collection)\n",
    "\n",
    "# Kiểm tra và in ra số lượng items đã được lưu vào collection\n",
    "result = collection.get(include=[\"metadatas\", \"embeddings\"])  # Lấy dữ liệu từ collection\n",
    "print(f\"Số lượng phần tử trong collection: {len(result['metadatas'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(min(100, len(result['metadatas']))):  # Hiển thị tối đa 5 phần tử\n",
    "    print(f\"Metadata {i+1}: {result['metadatas'][i]}\")  # In ra thông tin metadata của phần tử thứ i"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
